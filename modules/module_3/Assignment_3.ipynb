{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdp/aVwe1Qk6CzRIC7fW47",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamlidberg/Analyses-of-Environmental-Data-2/blob/main/modules/module_3/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling with Python\n",
        "Data is generated from multiple parts of society, but no one agrees on how to properly store data. It is often messy and semi-structured, and for any more extensive projects, you will spend most of the time acquiring, preparing and cleaning the data. Therefore the aim of this module is to introduce you to some tools and methods to handle datasets of different types, you will work on both tabular data, vector data and image data.\n",
        "\n",
        "\n",
        "All data using in this course will be \"real\" data. This means that is not always ready for analysis. For part of this excercise you will use data from the Swedish agency for Digital Goverment. https://www.dataportal.se/en It is still under construction but spend some time to poke around in there and see if you can find some inspiration for your future Master thesis.\n"
      ],
      "metadata": {
        "id": "SAlzGaz0X7ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data\n",
        "Students and researchers in Sweden have access to most of Swedens geographical data. You can use the [GET tool](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiX39fm752EAxX-GRAIHX1BCvYQFnoECBIQAQ&url=https%3A%2F%2Fmaps.slu.se%2F&usg=AOvVaw1f8lXxGJcMoJQd2BaJLK0N&opi=89978449) to select data, draw a square on a map and then download the data.\n",
        "\n",
        "### Task 1\n",
        "Download buildings from your favorite part of Sweden using the GET tool. Send me an mail if you fail to log in. you will need to download data from GET in module 4 as well so make sure you get this to work. On a scale between 1 to 5, how hard was it to download the data?"
      ],
      "metadata": {
        "id": "DBiPJVaR3Cap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Useful Linux commands\n",
        "Linux is the underlying kernel of the python envrionment so I wanted to introduce you to some usefull Linux commands that you can use in the terminal. If you want to use these commands in a notebook you need to use the ! sign infront.\n",
        "\n",
        "Linux commands are available in google colab, but if you are using anaconda on windows, you can install some basic Linux commands with conda install m2-base. Yet another reason to use Linux on your workstation. [Ubuntu](https://ubuntu.com/tutorials/install-ubuntu-desktop) is a good option if you have an old computer laying around. The support for Windows 10 ends this fall so there will be plenty of old but perfectly useable machines that you can aquire for your first workstation. Ask your nearest IT-department.\n"
      ],
      "metadata": {
        "id": "AnSHPPfEf05D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data with git clone\n",
        "Small datasets can be stored in github repositories. There are about 1000 images of impact creaters on the moon in this repository: https://github.com/williamlidberg/Unet-tutorial\n",
        "\n",
        "The flollowing command clones the repository including the data."
      ],
      "metadata": {
        "id": "33AnXSXYZFrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/williamlidberg/Unet-tutorial.git"
      ],
      "metadata": {
        "id": "Ol0YTrxNZPy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's always a good idea to inspect your data so lets plot some images using matplotlib"
      ],
      "metadata": {
        "id": "0jj5sS0lbIvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def plot_image_grid(image_dir, num_images=4, grid_size=(2, 2)):\n",
        "    image_files = [file for file in os.listdir(image_dir) if file.endswith(\".png\")][:num_images]\n",
        "\n",
        "    fig, axes = plt.subplots(*grid_size, figsize=(8, 8))\n",
        "\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        img = Image.open(os.path.join(image_dir, image_file)).convert('L')  # Convert to grayscale\n",
        "        row, col = divmod(i, grid_size[1])\n",
        "\n",
        "        axes[row, col].imshow(img, cmap='gray')\n",
        "        axes[row, col].axis(\"off\")\n",
        "        axes[row, col].set_title(image_file)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "image_directory = \"/content/Unet-tutorial/craters_1000_samples/train/images\"\n",
        "plot_image_grid(image_directory, num_images=4, grid_size=(2, 2))\n"
      ],
      "metadata": {
        "id": "OyHUBX9RaTjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data also contain images where each pixel is labeled 1 for impact craters and 0 for background. Lets quickly count the number of pixels labeled as impact crates across the dataset. Lets say we want to plot the distribution of the area of each image covered by impact craters."
      ],
      "metadata": {
        "id": "wWR7BxSlcN0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imageio.v2 as imageio\n",
        "sums = []\n",
        "\n",
        "label_directory = '/content/Unet-tutorial/craters_1000_samples/train/images'\n",
        "\n",
        "for image in os.listdir(label_directory):\n",
        "  image_with_path = os.path.join(label_directory, image)\n",
        "  numpy_array = imageio.imread(image_with_path)\n",
        "  sums.append(np.sum(numpy_array))\n",
        "\n",
        "plt.hist(sums, bins=10, color='blue', edgecolor='black', alpha=0.7)\n",
        "plt.title('Distribution of Total Values Across Images')\n",
        "plt.xlabel('Total Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EYLqGubScX6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2\n",
        "Clone this repository https://github.com/williamlidberg/Geographical-Intelligence and use numpy to find the maximum value in the digital elevation model stored under https://github.com/williamlidberg/Geographical-Intelligence/tree/main/data/rasters/dem"
      ],
      "metadata": {
        "id": "xf50dF_Ef8Nu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Download data with wget\n",
        "wget can be used to download files from the internet using a link and a target directory. The -P after the link indicates the path where the file should be stored, in this case under /content/sample_data/ if you are using google Colab."
      ],
      "metadata": {
        "id": "SL3xaArtZEmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://geodata.naturvardsverket.se/nedladdning/diken/Diken_Sverige/Diken_lansvis/Diken_K.zip -P /content/sample_data/\n"
      ],
      "metadata": {
        "id": "NhYioC5xuMDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unzip\n",
        "Unzip can be used to unpack ziped data. The flag -o means that the data will be overwritten if you already have a file with the same name."
      ],
      "metadata": {
        "id": "RJv2TUWdXmcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/sample_data/Diken_K.zip -d /content/"
      ],
      "metadata": {
        "id": "17qi2TjdXoyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".gpkg is a geopackage which is an open, standards-based, file format for storing geospatial data. It is designed to be a single-file container that can hold various types of geographic data, including vector features, raster images, and attribute tables. There has been a push to move away from shapefiles to geopackage. Python packages such as geopandas, fiona and gdal can be used to open geopackage files. We will dive deeper into geopandas in module 6 so for now lets just open the geopackage. Install geopandas if its not already installed."
      ],
      "metadata": {
        "id": "zgZVCweZhQtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "path_to_geopackage = '/content/Diken_K.gpkg'\n",
        "data = gpd.read_file(path_to_geopackage)\n",
        "data"
      ],
      "metadata": {
        "id": "8ib873kFirq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.plot()"
      ],
      "metadata": {
        "id": "1WX5Y0CC2PUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3\n",
        "Select another region of Sweden here and download it. https://geodata.naturvardsverket.se/nedladdning/diken/Diken_Sverige/Diken_lansvis/?C=N;O=A\n",
        "\n",
        "Awnser the question: What is the most common type of ditches in that area? The column with ditch type is named \"Typ\"."
      ],
      "metadata": {
        "id": "P_JaKs-q2at8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data with urllib\n",
        "urllib is a python package that collects several modules for working with URLs\n"
      ],
      "metadata": {
        "id": "FSduxVN42HNL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-EcTcZwX1Rf"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlretrieve\n",
        "url = ('https://opendata.umea.se/api/v2/catalog/datasets/vaxthusgasutslapp_umea/exports/csv')\n",
        "filename = '/content/sample_data/vaxthusgasutslapp_umea.csv' # you need to adjust this path on your own computer if you are using anaconda.\n",
        "\n",
        "urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In google colab the data is stored under '/content/sample_data/' but you need to specify a path on your own machine. R has built in functionality to read csv-files but in Python we need to use a library like pandas. Here we will import pandas as pd and then read the csv file using the command pd.read_csv()"
      ],
      "metadata": {
        "id": "iJotDbn0Y-tE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tabular data\n",
        "Tabular data refers to information organized in a table. Each row represents a single observation, entity, or record in the dataset. Each column represents a specific attribute, variable, or field associated with the observations. The R community sometimes refers to this as tidy data."
      ],
      "metadata": {
        "id": "QLrZjjo4_cW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ghg_emissions = pd.read_csv('/content/sample_data/vaxthusgasutslapp_umea.csv')"
      ],
      "metadata": {
        "id": "RdNv0RAmc_3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Something is off with this file. You can download it and try to open it in exceel or notepad to see what could be the issue but a common problem with CSV files is how the columns are separated. Especcially Swedish data where , is used instead of . for numbers. However, just like with R you can specify the separator in pandas. In this case we can try with ';'"
      ],
      "metadata": {
        "id": "1DEZ7SBRdCPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ghg_emissions = pd.read_csv('/content/sample_data/vaxthusgasutslapp_umea.csv', sep=';')\n",
        "ghg_emissions"
      ],
      "metadata": {
        "id": "oe_mk2FCc_8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that these columns are in Swedish so lets rename them to something more useful using the rename command. It takes the dataframe as input and then you pair up the old name with the new name seperated by :"
      ],
      "metadata": {
        "id": "Zit_z3qDay5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ghg_emissions.rename(columns={'huvudsektor': 'MainSector',\n",
        "                   'undersektor': 'SubSector',\n",
        "                   'artal': 'Year',\n",
        "                   'varde_co2e': 'CO2EmissionValue'}, inplace=True)\n",
        "ghg_emissions"
      ],
      "metadata": {
        "id": "jiL1scXaa71u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the column headers are in English but the content is still in Swedish. This can be a bit more cumbersum to fix but here is a demonstration of how you can replace Personbilar with cars in the Subsector column."
      ],
      "metadata": {
        "id": "aCbM1ts8Anhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ghg_emissions['SubSector'] = ghg_emissions['SubSector'].replace('Personbilar', 'Cars')\n",
        "ghg_emissions"
      ],
      "metadata": {
        "id": "Wl8BTrJFA8Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a quick overview of a pandas dataframe you can use the command describe(). \\\n",
        "\n",
        "If the DataFrame contains numerical data, the description contains these information for each column:\n",
        "\n",
        "* count - The number of not-empty values.\n",
        "* mean - The average (mean) value.\n",
        "* std - The standard deviation.\n",
        "* min - the minimum value.\n",
        "* 25% - The 25% percentile.\n",
        "* 50% - The 50% percentile.\n",
        "* 75% - The 75% percentile.\n",
        "* max - the maximum value."
      ],
      "metadata": {
        "id": "ZtKnkRnIXl6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ghg_emissions.describe()"
      ],
      "metadata": {
        "id": "nqBkTvEDacC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While this is usefull it does not always make sence. For example, we might want to have a summary per SubSector or year instead of all of them combined. This is where the command groupby shines. \\\n",
        "\n",
        "Group by 'MainSector' and calculate the sum of 'CO2EmissionValue'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8oz9QQ5zbY5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_df = ghg_emissions.groupby(['MainSector'])['CO2EmissionValue'].sum().reset_index()\n",
        "summarized_df"
      ],
      "metadata": {
        "id": "osRi0XaKcXrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying reset_index() will move the grouped columns into a new dataframe with new columns. This can be useful in many cases, especially if you want to work with the result as a regular DataFrame and not deal with a multi-level index."
      ],
      "metadata": {
        "id": "6UnebVrQjnIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4\n",
        "What was the total Co2 Emission in Umeå in 2017?"
      ],
      "metadata": {
        "id": "C4nEOCELez3B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2KfnyqNfpyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting data with Python\n",
        "R and ggplot are excellent for making beautiful plots and I sometimes go back to R for my figures. However, there are some nice tools for visualising data in Python as well. Matplotlib and seaborn is a nice combination of packages."
      ],
      "metadata": {
        "id": "zE-Hpy1PCDJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "!pip install seaborn"
      ],
      "metadata": {
        "id": "7OvAU7htEXpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets use the previously downloaded data ghg_emissions to make some plots. We can start by summarizing the emissions by year and create a barplot"
      ],
      "metadata": {
        "id": "feLZBGvWhr0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_emissions = ghg_emissions.groupby(['Year'])['CO2EmissionValue'].sum().reset_index()"
      ],
      "metadata": {
        "id": "TacHWKdn6GSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "sns.barplot(x='Year', y='CO2EmissionValue', data=yearly_emissions) # note that we use sns.barplot\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('CO2 Emissions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ggJuOjwA4pqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to group by multiple columns, you can pass a list of column names to the groupby method. Here's an example:"
      ],
      "metadata": {
        "id": "eued57dC7QHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_emissions = ghg_emissions.groupby(['Year', 'SubSector'])['CO2EmissionValue'].sum().reset_index()\n",
        "yearly_emissions"
      ],
      "metadata": {
        "id": "rbEQUJtv7Tkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can go even further and filter the dataframe for a specific value or class in the attribute table. Here is an example of how to find the emissions over time but only for the jordbruk (agriculture)"
      ],
      "metadata": {
        "id": "Lysl_KC28PDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column = 'Jordbruk'\n",
        "agriculture_emissions = ghg_emissions.loc[ghg_emissions['MainSector'] == column]\n",
        "agriculture_emissions"
      ],
      "metadata": {
        "id": "qV2N5OUx8ejb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "sns.boxplot(x='Year', y='CO2EmissionValue', data=agriculture_emissions) # note that we use sns.boxplot\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('CO2 Emissions from agriculture in Umeå')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BOIj_3aXF_je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering dataframes is a very powerful tool and you can filter with multiple conditions. For example you can select emissions from agriculture between different years."
      ],
      "metadata": {
        "id": "EW9XGqgUAcvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agriculture_subset = ghg_emissions.loc[(ghg_emissions['Year'] >= 2015) & (ghg_emissions['Year'] <= 2020)]"
      ],
      "metadata": {
        "id": "cXBPfi9UArQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "sns.boxplot(x='Year', y='CO2EmissionValue', data=agriculture_subset, showfliers=False) # Note that we exluded outliers this time\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('CO2 Emissions from agriculture in Umeå')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TF8nGYN5ahie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We cannot cover everything pandas can do here but one final example is to exclude rows in the dataframe. In this case we will exclude the main sector alla. This operation is called with != in python. e.i not equal."
      ],
      "metadata": {
        "id": "jAFdQmP_CtS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column = 'Alla'\n",
        "emissions = ghg_emissions.loc[ghg_emissions['MainSector'] != column]"
      ],
      "metadata": {
        "id": "_ptO_oHjC2Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "sns.boxplot(x='Year', y='CO2EmissionValue', data=emissions, showfliers=False) # Note that we exluded outliers this time\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Total CO2 Emissions from in Umeå')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XssT2acEDdxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5\n",
        "Make a boxplot of the Co2 emissions from the transportation sector (Transporter) in Umeå between 2015 and 2020 but exclude the emissions from busses (Bussar)."
      ],
      "metadata": {
        "id": "A4AXschuDs_A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMsw5Fz32KVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Animated plots\n",
        "If you really want to impress your friends you can flex with animated plots. Some of you might have heard of Hans Rosling and gapminder. Lets start with an example using gapminder data and then make an animation with our data."
      ],
      "metadata": {
        "id": "1s0wNhRUZmtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chart_studio"
      ],
      "metadata": {
        "id": "WYSvJ4g-aAP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df = px.data.gapminder() pulls the data from gampinder"
      ],
      "metadata": {
        "id": "CJPHdu68gszR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "df = px.data.gapminder()\n",
        "px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", animation_frame=\"year\", animation_group=\"country\",\n",
        "           size=\"pop\", color=\"continent\", hover_name=\"country\",\n",
        "           log_x=True, size_max=55, range_x=[100,100000], range_y=[25,90])"
      ],
      "metadata": {
        "id": "S-LHEw39cMBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First start by removing the column 'Alla' from the dataset and then sort the dataset by year."
      ],
      "metadata": {
        "id": "IZvwTzlRgz7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column = 'Alla'\n",
        "emissions = ghg_emissions.loc[ghg_emissions['MainSector'] != column]\n",
        "emissions_sorted = emissions.sort_values(by='Year')"
      ],
      "metadata": {
        "id": "O2TbSgibfh4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we can plot the data as an animation of emissions over time."
      ],
      "metadata": {
        "id": "ihpXU3Kpg-aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "df = px.data.gapminder()\n",
        "\n",
        "fig = px.bar(emissions_sorted, x=\"MainSector\", y=\"CO2EmissionValue\", color=\"MainSector\",\n",
        "  animation_frame=\"Year\", animation_group=\"MainSector\", range_y=[0,100000])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "xVcMHogBfajU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6\n",
        "Change the above animation to a boxplot instead of a barplot and set the theme to darkmode to make it extra cool. It is ok to use LLMs for his task."
      ],
      "metadata": {
        "id": "88K8aYLHh6Se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Animated maps\n",
        "Its also possible to create time series animation using geospatial data. Here is an example of planted trees in Umeå. The [tree dataset]((https://opendata.umea.se/explore/dataset/trad-som-forvaltas-av-gator-och-parker/export/?disjunctive.tradart_vetenskap_namn_1_1_2&disjunctive.tradart_svenskt_namn_1_1_3) is from Umeå kommun."
      ],
      "metadata": {
        "id": "Mcug8AjXGxxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 7\n",
        "Download the [tree dataset](https://opendata.umea.se/explore/dataset/trad-som-forvaltas-av-gator-och-parker/export/?disjunctive.tradart_vetenskap_namn_1_1_2&disjunctive.tradart_svenskt_namn_1_1_3) from Umeå\n"
      ],
      "metadata": {
        "id": "hEP2MaMD2kLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = ('https://opendata.umea.se/api/explore/v2.1/catalog/datasets/trad-som-forvaltas-av-gator-och-parker/exports/geojson?lang=en&timezone=Europe%2FStockholm')\n",
        "filename = '/content/sample_data/trees.geojson' # you need to adjust this path on your own computer if you are using anaconda.\n",
        "\n",
        "urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "R3uv1TB32lHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the geojson file using geopandas and create a basic plot."
      ],
      "metadata": {
        "id": "dfKPsKGaIgNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "\n",
        "# Load your geojson\n",
        "gdf = gpd.read_file(\"/content/sample_data/trees.geojson\")\n",
        "\n",
        "# Convert to DataFrame with lat/lon\n",
        "df = gdf.copy()\n",
        "df[\"lon\"] = gdf.geometry.x\n",
        "df[\"lat\"] = gdf.geometry.y\n",
        "\n",
        "fig = px.scatter_mapbox(\n",
        "    df,\n",
        "    lat=\"lat\",\n",
        "    lon=\"lon\",\n",
        "    color=\"gatu_eller_parktrad_1_4_4\",\n",
        "    animation_frame=\"planteringsdatum_6_1_1\",\n",
        "    mapbox_style=\"open-street-map\",\n",
        "    zoom=10\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    width=800,    # width in pixels\n",
        "    height=1000    # height in pixels\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "qMbQk4d443i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7\n",
        "There is a major campain with restoring wetlands in Sweden. Your final task is to make an animated map with restored wetlands over time. Download restored wetlands from the Swedish Forest Agency. Bellow is the code you need for downloading the data. Feel free to use another dataset if you want. For example, if you have a powerful computer and some patience you can create map annimations from all harvested forest in Sweden: https://geodpags.skogsstyrelsen.se/geodataport/data/sksUtfordAvverk_gpkg.zip\n",
        "\n"
      ],
      "metadata": {
        "id": "vMdao-5_Iqf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://geodpags.skogsstyrelsen.se/geodataport/data/sksAtervatningYta_gpkg.zip -P /content/sample_data/\n",
        "!unzip -o /content/sample_data/sksAtervatningYta_gpkg.zip -d /content/\n",
        "gdf = gpd.read_file(\"/content/sksAtervatningYta.gpkg\")\n",
        "print(gdf.columns)"
      ],
      "metadata": {
        "id": "ixR_rTaL4j6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data is stored as polygons of the wetlands but for our task we only need the coordiantes. Here we use geopandas to extract the centroid coordinates. Ignore the warning."
      ],
      "metadata": {
        "id": "sE_GNgkxJ1hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf = gpd.read_file(\"/content/sksAtervatningYta.gpkg\")\n",
        "\n",
        "# Reproject back to WGS84 for plotting\n",
        "gdf = gdf_proj.to_crs(epsg=4326)\n",
        "\n",
        "# Extract lon/lat\n",
        "gdf[\"lon\"] = gdf.centroid.x\n",
        "gdf[\"lat\"] = gdf.centroid.y\n",
        "\n"
      ],
      "metadata": {
        "id": "Kj-rFejgDxLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make an animated map of restored wetlands where the size is controled by \"KartaHektar\" (area) , color is \"Kommun\" (municipality) and the time series is \"AvtalatDatum\" (date of contract)."
      ],
      "metadata": {
        "id": "6c7f_hSIKYeC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wh5UrKclEmGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}